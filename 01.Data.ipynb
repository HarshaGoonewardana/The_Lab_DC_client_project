{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Client Project: The Lab @ DC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Title: Predicting Shots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authors: Kihoon Sohn, Brian Collins, Harsha Goonawardana, Priya Kakkar\n",
    "- Cohorts of the Data Science Immersive, General Assembly @ Washington DC campus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we pull the raw data from Open Data DC and the Metropolitan Police Department (MPD) and transform and clean them for our analysis. **This is notebook 1 of 3.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import basic libraries\n",
    "\n",
    "import pandas as pd\n",
    "import os, os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the path for the datasets.\n",
    "\n",
    "csr_path = \"assets/csr/\"\n",
    "mpd_path = \"assets/mpd/\"\n",
    "os.makedirs(csr_path, exist_ok=True)\n",
    "os.makedirs(mpd_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read CSVs\n",
    "##### 1) Source: Open Data DC - City Service Requests datasets\n",
    "- All datasets from Open Data DC are over 100mb, therefore it will not fit in your remote github due to the size limitation. \n",
    "- The following code enables you to download the file from the URLs and save it to your local machine, so that you don't need to fetch it from the web everytime you run the notebook.\n",
    "- **Make sure have `.gitignore` file in your local repo** so that the downloaded `big-size-CSVs` won't push it back to your remote repo. **Please check with the instruction from `README.md`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once you have a dataset in your local machine, it will be loaded it up directly.\n",
    "# if not, download the datasets directly from City Service Requests, OpenData DC(http://opendata.dc.gov/) \n",
    "\n",
    "# City Service Requests 2014 datasets\n",
    "if os.path.isfile('./assets/csr/CSR_2014.csv') == True:\n",
    "    csr_2014 = pd.read_csv('./assets/csr/CSR_2014.csv', low_memory=False)\n",
    "else:\n",
    "    csr_2014 = pd.read_csv('https://opendata.arcgis.com/datasets/17cafb3ffab347409def7e85e14c56bd_5.csv', low_memory=False)\n",
    "    csr_2014.to_csv('./assets/csr/CSR_2014.csv', index=False)\n",
    "\n",
    "# City Service Requests 2015 datasets\n",
    "if os.path.isfile('./assets/csr/CSR_2015.csv') == True:\n",
    "    csr_2015 = pd.read_csv('./assets/csr/CSR_2015.csv', low_memory=False)\n",
    "else:\n",
    "    csr_2015 = pd.read_csv('https://opendata.arcgis.com/datasets/b93ec7fc97734265a2da7da341f1bba2_6.csv', low_memory=False)\n",
    "    csr_2015.to_csv('./assets/csr/CSR_2015.csv', index=False)\n",
    "\n",
    "# City Service Requests 2016 datasets\n",
    "if os.path.isfile('./assets/csr/CSR_2016.csv') == True:\n",
    "    csr_2016 = pd.read_csv('./assets/csr/CSR_2016.csv', low_memory=False)\n",
    "else:\n",
    "    csr_2016 = pd.read_csv('https://opendata.arcgis.com/datasets/0e4b7d3a83b94a178b3d1f015db901ee_7.csv', low_memory=False)\n",
    "    csr_2016.to_csv('./assets/csr/CSR_2016.csv', index=False)\n",
    "\n",
    "# City Service Requests 2017 datasets\n",
    "if os.path.isfile('./assets/csr/CSR_2017.csv') == True:\n",
    "    csr_2017 = pd.read_csv('./assets/csr/CSR_2017.csv', low_memory=False)\n",
    "else:\n",
    "    csr_2017 = pd.read_csv('https://opendata.arcgis.com/datasets/19905e2b0e1140ec9ce8437776feb595_8.csv', low_memory=False)\n",
    "    csr_2017.to_csv('./assets/csr/CSR_2017.csv', index=False)\n",
    "\n",
    "# City Service Requests 2018 Q1 datasets\n",
    "if os.path.isfile('./assets/csr/CSR_2018_q1.csv') == True:\n",
    "    csr_2018_q1 = pd.read_csv('./assets/csr/CSR_2018_q1.csv', low_memory=False)\n",
    "else:\n",
    "    csr_2018_q1 = pd.read_csv('https://opendata.arcgis.com/datasets/2a46f1f1aad04940b83e75e744eb3b09_9.csv', low_memory=False)\n",
    "    csr_2018_q1.to_csv('./assets/csr/CSR_2018_q1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) Source: Metropolitan Police Department - ShotSpotters datasets\n",
    "- https://mpdc.dc.gov/publication/shotspotter-data-disclaimer-and-dictionary\n",
    "- You will find the datasets at `./assets/` folder in the git repo and no need to download it from the web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unmute and run this code below if you have problem `.read_excel` \n",
    "\n",
    "# !pip install xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ShotSpotters datasets from Metropolitan Police Department \n",
    "\n",
    "# Train set: ShotSpotters datasets for 2014 - 2017 \n",
    "shots_2014 = pd.read_excel('./assets/mpd/ShotSpotter Data 14-17 180213_0.xlsx', sheet_name=0)\n",
    "shots_2015 = pd.read_excel('./assets/mpd/ShotSpotter Data 14-17 180213_0.xlsx', sheet_name=1)\n",
    "shots_2016 = pd.read_excel('./assets/mpd/ShotSpotter Data 14-17 180213_0.xlsx', sheet_name=2)\n",
    "shots_2017 = pd.read_excel('./assets/mpd/ShotSpotter Data 14-17 180213_0.xlsx', sheet_name=3)\n",
    "\n",
    "# Test set: ShotSpotters datasets for 2018 Q1 \n",
    "shots_2018_q1 = pd.read_excel('./assets/mpd/ShotSpotter Public Data Q1 2018.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic settings with the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "csr_2014.name      = 'City Service Requests 2014 data'\n",
    "csr_2015.name      = 'City Service Requests 2015 data'\n",
    "csr_2016.name      = 'City Service Requests 2016 data'\n",
    "csr_2017.name      = 'City Service Requests 2017 data'\n",
    "csr_2018_q1.name   = 'City Service Requests 2018 Q1 data'\n",
    "shots_2014.name    = 'Shot Spotters 2014 data'\n",
    "shots_2015.name    = 'Shot Spotters 2015 data'\n",
    "shots_2016.name    = 'Shot Spotters 2016 data'\n",
    "shots_2017.name    = 'Shot Spotters 2017 data'\n",
    "shots_2018_q1.name = 'Shot Spotters 2018 Q1 data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that no datasets have `Unnamed: 0` columns in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped unnamed column in City Service Requests 2014 data\n",
      "Dropped unnamed column in City Service Requests 2015 data\n",
      "Dropped unnamed column in City Service Requests 2016 data\n",
      "Dropped unnamed column in City Service Requests 2017 data\n",
      "Dropped unnamed column in City Service Requests 2018 Q1 data\n",
      "No columns dropped in Shot Spotters 2014 data\n",
      "No columns dropped in Shot Spotters 2015 data\n",
      "No columns dropped in Shot Spotters 2016 data\n",
      "No columns dropped in Shot Spotters 2017 data\n",
      "No columns dropped in Shot Spotters 2018 Q1 data\n"
     ]
    }
   ],
   "source": [
    "for df_ in [csr_2014, csr_2015, csr_2016, csr_2017, csr_2018_q1, shots_2014, shots_2015, shots_2016, shots_2017, shots_2018_q1]:\n",
    "    if df_.columns[0] == \"Unnamed: 0\":\n",
    "        df_.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "        print(\"Dropped unnamed column in\", df_.name)\n",
    "    else:\n",
    "        print(\"No columns dropped in\", df_.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the shapes of the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of City Service Requests 2014   :  (322469, 30)\n",
      "Shape of City Service Requests 2015   :  (295633, 30)\n",
      "Shape of City Service Requests 2016   :  (302985, 30)\n",
      "Shape of City Service Requests 2017   :  (310146, 30)\n",
      "Shape of City Service Requests 2018 Q1:  (152796, 30)\n",
      "--------------------\n",
      "Shape of Shot Spotters 2014   :  (9637, 7)\n",
      "Shape of Shot Spotters 2015   :  (7952, 7)\n",
      "Shape of Shot Spotters 2016   :  (5872, 7)\n",
      "Shape of Shot Spotters 2017   :  (4882, 7)\n",
      "Shape of Shot Spotters 2018 Q1:  (1072, 7)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of City Service Requests 2014   : \", csr_2014.shape)\n",
    "print(\"Shape of City Service Requests 2015   : \", csr_2015.shape)\n",
    "print(\"Shape of City Service Requests 2016   : \", csr_2016.shape)\n",
    "print(\"Shape of City Service Requests 2017   : \", csr_2017.shape)\n",
    "print(\"Shape of City Service Requests 2018 Q1: \", csr_2018_q1.shape)\n",
    "print(\"--------------------\")\n",
    "print(\"Shape of Shot Spotters 2014   : \", shots_2014.shape)\n",
    "print(\"Shape of Shot Spotters 2015   : \", shots_2015.shape)\n",
    "print(\"Shape of Shot Spotters 2016   : \", shots_2016.shape)\n",
    "print(\"Shape of Shot Spotters 2017   : \", shots_2017.shape)\n",
    "print(\"Shape of Shot Spotters 2018 Q1: \", shots_2018_q1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "High likely the City Service Requests datasets are aligned in its columns name, but just make sure to check it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "csr_2015 = csr_2015[csr_2014.columns]\n",
    "csr_2016 = csr_2016[csr_2015.columns]\n",
    "csr_2017 = csr_2017[csr_2016.columns]\n",
    "csr_2018_q1 = csr_2018_q1[csr_2017.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSR train set shape   :  (1231233, 30)\n",
      "CSR test set shape    :  (152796, 30)\n",
      "Shots train set shape :  (28343, 7)\n",
      "Shots test set shape  :  (1072, 7)\n"
     ]
    }
   ],
   "source": [
    "# concat the datasets\n",
    "csr = [csr_2014, csr_2015, csr_2016, csr_2017]\n",
    "\n",
    "csr_train = pd.concat(csr)\n",
    "print(\"CSR train set shape   : \", csr_train.shape)\n",
    "\n",
    "csr_test = csr_2018_q1\n",
    "print(\"CSR test set shape    : \", csr_test.shape)\n",
    "\n",
    "shots = [shots_2014, shots_2015, shots_2016, shots_2017]\n",
    "shots_train = pd.concat(shots)\n",
    "print(\"Shots train set shape : \", shots_train.shape)\n",
    "\n",
    "shots_test = shots_2018_q1\n",
    "print(\"Shots test set shape  : \", shots_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'Type', 'Date', 'Time', 'Source', 'Lat (100)', 'Lon (100)'], dtype='object')\n",
      "Index(['ID', 'Type', 'Date', 'Time', 'Source', 'Lat (100m)', 'Lon (100m)'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# check ShotSpotters datasets columns\n",
    "print(shots_train.columns)\n",
    "print(shots_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure to rename it\n",
    "shots_train = shots_train.rename(columns={'Lat (100)': 'Latitude', 'Lon (100)': 'Longitude'})\n",
    "shots_test = shots_test.rename(columns={'Lat (100m)': 'Latitude', 'Lon (100m)': 'Longitude'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save it to CSVs (please proceed with the 2nd notebook for the EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "csr_train.to_csv('./assets/csr/csr_train.csv', index=False)\n",
    "csr_test.to_csv('./assets/csr/csr_test.csv', index=False)\n",
    "shots_train.to_csv('./assets/mpd/shots_train.csv', index=False)\n",
    "shots_test.to_csv('./assets/mpd/shots_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
