{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import CSV and EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'./assets/Housing_Data_3.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b19b80ca7df6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Import Housing data from https://www.redfin.com/blog/data-center\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./assets/Housing_Data_3.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/dsi/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/dsi/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/dsi/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    816\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/dsi/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/dsi/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1693\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'./assets/Housing_Data_3.csv' does not exist"
     ]
    }
   ],
   "source": [
    "#Import Housing data from https://www.redfin.com/blog/data-center\n",
    "df=pd.read_csv('./assets/Housing_Data_3.csv')\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix messy column names \n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\n",
    "# df.columns=[x.lower() for x in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#56 unique districts same as PSAs\n",
    "df.region.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#null value check\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.shape # 8/2012 dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check no more null values\n",
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Differentiate numerical and categorical features for further EDA\n",
    "ob_features = df.select_dtypes(include = [\"object\"]).columns\n",
    "num_features = df.select_dtypes(exclude = [\"object\"]).columns\n",
    "ob_features = [e for e in ob_features if e not in ('region', 'month_of_period_end')]\n",
    "\n",
    "print(\"Numerical features : \" + str(len(num_features)))\n",
    "print(\"Object features : \" + str(len(ob_features)))\n",
    "# df_num = df[ob_features]\n",
    "# df_ob = df[num_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seperate months and year\n",
    "df_year=df['month_of_period_end'].str.split(\"-\", n=2, expand=True)\n",
    "\n",
    "df_year['year']=df_year[0].astype('int64')\n",
    "\n",
    "df_year['year'] = df_year['year'].apply(lambda x: x+2000)\n",
    "\n",
    "df_year.drop(0,axis=1,inplace=True)\n",
    "\n",
    "df_year.rename(columns={1:'month'},inplace=True)\n",
    "print(df_year.head())\n",
    "\n",
    "#add the year and date back to the dataframe \n",
    "df=pd.concat([df_year,df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the order fo the columns \n",
    "#attribute: https://stackoverflow.com/questions/13148429/how-to-change-the-order-of-dataframe-columns\n",
    "def change_column_order(df, col_name, index):\n",
    "    cols = df.columns.tolist()\n",
    "    cols.remove(col_name)\n",
    "    cols.insert(index, col_name)\n",
    "    return df[cols]\n",
    "df = change_column_order(df, 'region', 0)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-4ab9d9a3ff31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Prepare object columns for conversion and convert\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mob_features\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mob_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'\\$'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'%'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'K'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mob_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Prepare object columns for conversion and convert\n",
    "df[ob_features] = df[ob_features].replace({'\\$': '','%': '', 'K': '',',':''}, regex=True)\n",
    "for col in ob_features:\n",
    "    df[col]=df[col].astype('float32',)\n",
    "df.info(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-9447ae629b41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.round(decimals=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#after checking that the date matches .. drop \"month_of_period_end\"\n",
    "df=df.drop('month_of_period_end',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing values \n",
      " region                      0\n",
      "month                       0\n",
      "year                        0\n",
      "median_sale_price           0\n",
      "median_sale_price_mom       0\n",
      "median_sale_price_yoy       0\n",
      "homes_sold                  0\n",
      "homes_sold_mom              0\n",
      "homes_sold_yoy              0\n",
      "new_listings                0\n",
      "new_listings_mom            0\n",
      "new_listings_yoy            0\n",
      "inventory                   0\n",
      "inventory_mom               0\n",
      "inventory_yoy               0\n",
      "days_on_market              0\n",
      "days_on_market_mom          0\n",
      "days_on_market_yoy          0\n",
      "average_sale_to_list        0\n",
      "average_sale_to_list_mom    0\n",
      "average_sale_to_list_yoy    0\n",
      "dtype: int64\n",
      "dataframe index \n",
      " Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n",
      "            ...\n",
      "            2902, 2903, 2904, 2905, 2906, 2907, 2908, 2909, 2910, 2911],\n",
      "           dtype='int64', length=2904)\n",
      "dataframe types \n",
      " region                       object\n",
      "month                        object\n",
      "year                          int64\n",
      "median_sale_price           float32\n",
      "median_sale_price_mom       float32\n",
      "median_sale_price_yoy       float32\n",
      "homes_sold                  float32\n",
      "homes_sold_mom              float32\n",
      "homes_sold_yoy              float32\n",
      "new_listings                float32\n",
      "new_listings_mom            float32\n",
      "new_listings_yoy            float32\n",
      "inventory                   float32\n",
      "inventory_mom               float32\n",
      "inventory_yoy               float32\n",
      "days_on_market                int64\n",
      "days_on_market_mom            int64\n",
      "days_on_market_yoy            int64\n",
      "average_sale_to_list        float32\n",
      "average_sale_to_list_mom    float32\n",
      "average_sale_to_list_yoy    float32\n",
      "dtype: object\n",
      "dataframe shape \n",
      " (2904, 21)\n",
      "dataframe describe \n",
      "               year  median_sale_price  median_sale_price_mom  \\\n",
      "count  2904.000000        2904.000000            2904.000000   \n",
      "mean   2015.690427         518.073364               1.425344   \n",
      "std       1.262443         247.651474              16.612694   \n",
      "min    2014.000000          70.000000             -69.500000   \n",
      "25%    2015.000000         368.750000              -3.300000   \n",
      "50%    2016.000000         480.000000               0.000000   \n",
      "75%    2017.000000         612.250000               4.225000   \n",
      "max    2018.000000        2198.000000             276.000000   \n",
      "\n",
      "       median_sale_price_yoy    homes_sold  homes_sold_mom  homes_sold_yoy  \\\n",
      "count            2904.000000   2904.000000     2904.000000     2904.000000   \n",
      "mean                8.129615    210.862610        2.337741       13.095660   \n",
      "std                28.105270    958.849182       20.536263       48.434284   \n",
      "min               -79.099998      2.000000      -64.300003      -86.400002   \n",
      "25%                -2.025000     26.000000      -10.500000      -11.100000   \n",
      "50%                 5.300000     45.000000        0.000000        5.800000   \n",
      "75%                14.600000     73.000000       12.500000       25.299999   \n",
      "max               494.299988  10986.000000      166.699997      866.700012   \n",
      "\n",
      "       new_listings  new_listings_mom  new_listings_yoy     inventory  \\\n",
      "count   2904.000000       2904.000000       2904.000000   2904.000000   \n",
      "mean     262.783417          3.492527         10.214945    409.629120   \n",
      "std     1232.309082         23.434641         36.211880   2631.296631   \n",
      "min        3.000000        -62.500000        -77.800003      1.000000   \n",
      "25%       31.000000        -10.900000        -10.400000     18.000000   \n",
      "50%       53.000000          0.000000          4.600000     30.000000   \n",
      "75%       89.000000         14.700000         21.824999     54.000000   \n",
      "max    13375.000000        160.000000        350.000000  25140.000000   \n",
      "\n",
      "       inventory_mom  inventory_yoy  days_on_market  days_on_market_mom  \\\n",
      "count    2904.000000    2904.000000     2904.000000         2904.000000   \n",
      "mean        3.375310      10.271832       26.320592            0.027204   \n",
      "std        27.541452      43.241554       17.365521           12.443587   \n",
      "min       -75.000000     -92.300003        5.000000         -121.000000   \n",
      "25%       -11.800000     -15.000000       15.000000           -4.000000   \n",
      "50%         0.000000       3.250000       22.000000            0.000000   \n",
      "75%        14.300000      26.700001       33.000000            4.000000   \n",
      "max       500.000000     500.000000      217.000000          118.000000   \n",
      "\n",
      "       days_on_market_yoy  average_sale_to_list  average_sale_to_list_mom  \\\n",
      "count         2904.000000           2904.000000               2904.000000   \n",
      "mean            -0.813361             99.526901                  0.007128   \n",
      "std             21.287000              1.791763                  1.223859   \n",
      "min           -155.000000             89.000000                -10.400000   \n",
      "25%             -8.000000             98.699997                 -0.500000   \n",
      "50%              0.000000             99.599998                  0.000000   \n",
      "75%              7.000000            100.500000                  0.500000   \n",
      "max            168.000000            111.400002                 16.299999   \n",
      "\n",
      "       average_sale_to_list_yoy  \n",
      "count               2904.000000  \n",
      "mean                   0.103719  \n",
      "std                    2.218013  \n",
      "min                  -13.300000  \n",
      "25%                   -0.800000  \n",
      "50%                    0.100000  \n",
      "75%                    1.000000  \n",
      "max                   12.400000  \n",
      "region\n",
      "56\n",
      "month\n",
      "12\n",
      "year\n",
      "5\n",
      "median_sale_price\n",
      "762\n",
      "median_sale_price_mom\n",
      "519\n",
      "median_sale_price_yoy\n",
      "805\n",
      "homes_sold\n",
      "385\n",
      "homes_sold_mom\n",
      "648\n",
      "homes_sold_yoy\n",
      "891\n",
      "new_listings\n",
      "413\n",
      "new_listings_mom\n",
      "779\n",
      "new_listings_yoy\n",
      "900\n",
      "inventory\n",
      "313\n",
      "inventory_mom\n",
      "653\n",
      "inventory_yoy\n",
      "846\n",
      "days_on_market\n",
      "104\n",
      "days_on_market_mom\n",
      "112\n",
      "days_on_market_yoy\n",
      "170\n",
      "average_sale_to_list\n",
      "139\n",
      "average_sale_to_list_mom\n",
      "109\n",
      "average_sale_to_list_yoy\n",
      "177\n"
     ]
    }
   ],
   "source": [
    "def eda(dataframe): #Credit: Ritika Bhasker, DSI alum\n",
    "    print (\"missing values \\n\", dataframe.isnull().sum())\n",
    "    print (\"dataframe index \\n\", dataframe.index)\n",
    "    print (\"dataframe types \\n\", dataframe.dtypes)\n",
    "    print (\"dataframe shape \\n\", dataframe.shape)\n",
    "    print (\"dataframe describe \\n\", dataframe.describe())\n",
    "    for item in dataframe:\n",
    "        print (item)\n",
    "        print (dataframe[item].nunique())\n",
    "eda(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to pickle \n",
    "import pickle \n",
    "df.to_pickle(\"./assets/housing_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "export = ['region', 'month', 'year','median_sale_price','homes_sold','homes_sold_mom','days_on_market','average_sale_to_list_mom']\n",
    "df_house_for_merge=df[export]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2904, 8)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_house_for_merge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_house_for_merge.to_pickle(\"./assets/housing_data_merge.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"./assets/housing_data_merge.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.set_index('region', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Washington, DC metro area', 'Washington, DC - Northwest Washington', 'Washington, DC - Southwest Washington',\n",
    "         'Washington, DC - Southeast Washington', 'Washington, DC - Northeast Washington', ''], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "psa = {'Washington, DC - Trinidad-Langston': '506',\n",
    "       'Washington, DC - Greenway / Benning / Dupont Park / River Terrace': '507',\n",
    "       'Washington, DC - Douglas / Shipley Terrace': '502',\n",
    "       'Washington, DC - American University Park / Friendship Heights / Tenleytown': '205',\n",
    "       'Washington, DC - Van Ness / Forest Hills / Wakefield': '205',\n",
    "       'Washington, DC - U-Street': '205',\n",
    "       'Washington, DC - Brightwood Park / Crestwood / Petworth': '404',\n",
    "       'Washington, DC - Foggy Bottom / George Washington University / West End': '207',\n",
    "       'Washington, DC - Woodridge / Fort Lincoln': '503', \n",
    "       'Washington, DC - Brentwood / Brookland / Langdon': '505',\n",
    "       'Washington, DC - Woodridge-Fort Lincoln': '503',\n",
    "       'Washington, DC - Bloomingdale / Eckington / Edgewood / Truxton Circle': '502',\n",
    "       'Washington, DC - Woodridge-Fort Lincoln': '503',\n",
    "       'Washington, DC - Glover Park': '205', \n",
    "       'Washington, DC - Bloomingdale / Eckington / Edgewood / Truxton Circle': '502',\n",
    "       'Washington, DC - Hillcrest / Fairfax Village / Naylor Gardens / Summit Park': '208',\n",
    "       'Washington, DC - Glover Park / Cathedral Heights / McLean Gardens': '205',\n",
    "       'Washington, DC - Michigan Park / University Heights': '306',\n",
    "       'Washington, DC - Logan Circle-Shaw': '307',\n",
    "       'Washington, DC - Kalorama': '208',\n",
    "       'Washington, DC - Cathedral-Wesley Heights-McLean Gardens': '205',\n",
    "       'Washington, DC - Brightwood / Manor Park / Takoma': '401',\n",
    "       'Washington, DC - Union Station / Kingman Park / Stanton Park': '103',\n",
    "       'Washington, DC - Benning Heights / Capitol View / Marshall Heights': '507',\n",
    "       'Washington, DC - Hillcrest-Fairfax Village': '606',\n",
    "       'Washington, DC - Southeast Chevy Chase': '201',\n",
    "       'Washington, DC - Hillbrook / Mayfair / Mahaning Heights': '205',\n",
    "       'Washington, DC - Columbia Heights / Mount Pleasant / Park View': '208',\n",
    "       'Washington, DC - Cleveland Park / Woodley Park / Embassy Row': '204',\n",
    "       'Washington, DC - Berry Farm / Buena Vista / Sheridan': '402',\n",
    "       'Washington, DC - Southwest Ballpark-Navy Yard': '107',\n",
    "       'Washington, DC - 16th Street Heights-Crestwood-Brightwood Park': '207',\n",
    "       'Washington, DC - Deanwood': '602',\n",
    "       'Washington, DC - Adams Morgan / Kalorama Heights / Lanier Heights': '303',\n",
    "       'Washington, DC - LeDroit Park-Bloomingdale': '306',\n",
    "       'Washington, DC - Kingman Park': '103',\n",
    "       'Washington, DC - Chevy Chase-DC': '201',\n",
    "       'Washington, DC - Colonial Village / Sheperd Park': '404',\n",
    "       'Washington, DC - Howard University / Le Droit Park': '306',\n",
    "       'Washington, DC - H Street-NoMa': '502',\n",
    "       'Washington, DC - Downtown-Penn Quarter-Chinatown': '208',\n",
    "       'Washington, DC - Foxhall-Palisades': '205',\n",
    "       'Washington, DC - Bellevue / Congress Heights / Washington Highlands': '204',\n",
    "       'Washington, DC - Fairlawn / Twining / Randle Highlands / Penn Branch': '607',\n",
    "       'Washington, DC - Foggy Bottom-Gwu-West End': '207',\n",
    "       'Washington, DC - Fort Totten-Riggs Park': '405',\n",
    "       'Washington, DC - River Terrace-Lily Ponds-Mayfair': '202',\n",
    "       'Washington, DC - Trinidad / Arboretum / Ivy City': '503',\n",
    "       'Washington, DC - Chinatown / Mount Vernon Square / Penn Quarter': '102',\n",
    "       'Washington, DC - Foxhall / Palisades / Spring Valley / Wesley Heights': '205', \n",
    "       'Washington, DC - Fort Totten / Lamont Riggs / Pleasant Hill / Queens Chapel': '208',\n",
    "       'Washington, DC - Takoma': '401',\n",
    "       'Washington, DC - Navy Yard': '107'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.region = df.region.map(psa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'region': 'PSA'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('./assets/housing_data_psa.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2644, 8)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
