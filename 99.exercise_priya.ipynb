{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Client Project: The Lab @ DC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authors: Kihoon Sohn\n",
    "- Data Science Immersive student, General Assembly @ Washington DC campus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we would like to pull addtional data into the project. This notebook is written instruction purpose for Priya. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import basic libraries\n",
    "\n",
    "import pandas as pd\n",
    "import os, os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the path for the datasets.\n",
    "pv_path = \"assets/pv\"\n",
    "\n",
    "# create Parking Violation folder\n",
    "os.makedirs(pv_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read CSVs\n",
    "##### 3) Source: Open Data DC - Parking Violations datasets\n",
    "- All datasets from Open Data DC are over 100mb, therefore it will not fit in your remote github due to the size limitation. \n",
    "- The following code enables you to download the file from the URLs and save it to your local machine, so that you don't need to fetch it from the web everytime you run the notebook.\n",
    "- **Make sure have `.gitignore` file in your local repo** so that the downloaded `big-size-CSVs` won't push it back to your remote repo. **Please check with the instruction from `README.md`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First set the local and original file directory and name\n",
    "\n",
    "# local directory\n",
    "\n",
    "pv_2014_01_local = './assets/pv/PV_Jan_2014.csv'\n",
    "pv_2014_02_local = './assets/pv/PV_Feb_2014.csv'\n",
    "pv_2014_03_local = './assets/pv/PV_Mar_2014.csv'\n",
    "pv_2014_04_local = './assets/pv/PV_Apr_2014.csv'\n",
    "pv_2014_05_local = './assets/pv/PV_May_2014.csv'\n",
    "pv_2014_06_local = './assets/pv/PV_Jun_2014.csv'\n",
    "pv_2014_07_local = './assets/pv/PV_Jul_2014.csv'\n",
    "pv_2014_08_local = './assets/pv/PV_Aug_2014.csv'\n",
    "pv_2014_09_local = './assets/pv/PV_Sep_2014.csv'\n",
    "pv_2014_10_local = './assets/pv/PV_Oct_2014.csv'\n",
    "pv_2014_11_local = './assets/pv/PV_Nov_2014.csv'\n",
    "pv_2014_12_local = './assets/pv/PV_Dec_2014.csv'\n",
    "\n",
    "pv_2015_01_local = './assets/pv/PV_Jan_2015.csv'\n",
    "pv_2015_02_local = './assets/pv/PV_Feb_2015.csv'\n",
    "pv_2015_03_local = './assets/pv/PV_Mar_2015.csv'\n",
    "pv_2015_04_local = './assets/pv/PV_Apr_2015.csv'\n",
    "pv_2015_05_local = './assets/pv/PV_May_2015.csv'\n",
    "pv_2015_06_local = './assets/pv/PV_Jun_2015.csv'\n",
    "pv_2015_07_local = './assets/pv/PV_Jul_2015.csv'\n",
    "pv_2015_08_local = './assets/pv/PV_Aug_2015.csv'\n",
    "pv_2015_09_local = './assets/pv/PV_Sep_2015.csv'\n",
    "pv_2015_10_local = './assets/pv/PV_Oct_2015.csv'\n",
    "pv_2015_11_local = './assets/pv/PV_Nov_2015.csv'\n",
    "pv_2015_12_local = './assets/pv/PV_Dec_2015.csv'\n",
    "\n",
    "pv_2016_01_local = './assets/pv/PV_Jan_2016.csv'\n",
    "pv_2016_02_local = './assets/pv/PV_Feb_2016.csv'\n",
    "pv_2016_03_local = './assets/pv/PV_Mar_2016.csv'\n",
    "pv_2016_04_local = './assets/pv/PV_Apr_2016.csv'\n",
    "pv_2016_05_local = './assets/pv/PV_May_2016.csv'\n",
    "pv_2016_06_local = './assets/pv/PV_Jun_2016.csv'\n",
    "pv_2016_07_local = './assets/pv/PV_Jul_2016.csv'\n",
    "pv_2016_08_local = './assets/pv/PV_Aug_2016.csv'\n",
    "pv_2016_09_local = './assets/pv/PV_Sep_2016.csv'\n",
    "pv_2016_10_local = './assets/pv/PV_Oct_2016.csv'\n",
    "pv_2016_11_local = './assets/pv/PV_Nov_2016.csv'\n",
    "pv_2016_12_local = './assets/pv/PV_Dec_2016.csv'\n",
    "\n",
    "pv_2017_01_local = './assets/pv/PV_Jan_2017.csv'\n",
    "pv_2017_02_local = './assets/pv/PV_Feb_2017.csv'\n",
    "pv_2017_03_local = './assets/pv/PV_Mar_2017.csv'\n",
    "pv_2017_04_local = './assets/pv/PV_Apr_2017.csv'\n",
    "pv_2017_05_local = './assets/pv/PV_May_2017.csv'\n",
    "pv_2017_06_local = './assets/pv/PV_Jun_2017.csv'\n",
    "pv_2017_07_local = './assets/pv/PV_Jul_2017.csv'\n",
    "pv_2017_08_local = './assets/pv/PV_Aug_2017.csv'\n",
    "pv_2017_09_local = './assets/pv/PV_Sep_2017.csv'\n",
    "pv_2017_10_local = './assets/pv/PV_Oct_2017.csv'\n",
    "pv_2017_11_local = './assets/pv/PV_Nov_2017.csv'\n",
    "pv_2017_12_local = './assets/pv/PV_Dec_2017.csv'\n",
    "\n",
    "pv_2018_01_local = './assets/pv/PV_Jan_2018.csv'\n",
    "pv_2018_02_local = './assets/pv/PV_Feb_2018.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original directory\n",
    "\n",
    "pv_2014_01_origin = 'https://opendata.arcgis.com/datasets/93c1160a13cd49e0a411b3f8e6c3be66_0.csv'\n",
    "pv_2014_03_origin = 'https://opendata.arcgis.com/datasets/863a00cfb1384e4288f3f6a53b63c5f1_2.csv'\n",
    "pv_2014_04_origin = 'https://opendata.arcgis.com/datasets/f01f547123844b97930de0127555ba64_3.csv'\n",
    "pv_2014_05_origin = 'https://opendata.arcgis.com/datasets/25d65f5cb95e492ea718e1764cf5c9a2_4.csv'\n",
    "pv_2014_06_origin = 'https://opendata.arcgis.com/datasets/39a65bd2f4ae43ce9dd9da7c209dbf29_5.csv'\n",
    "pv_2014_07_origin = 'https://opendata.arcgis.com/datasets/3f557f661e444c29b217eb63c2324d34_6.csv'\n",
    "pv_2014_08_origin = 'https://opendata.arcgis.com/datasets/dda2ff2bbcdb40a7a2044010f73f962b_7.csv'\n",
    "pv_2014_09_origin = 'https://opendata.arcgis.com/datasets/d60447c91b4649b892fc56c4b9d9ed96_8.csv'\n",
    "pv_2014_10_origin = 'https://opendata.arcgis.com/datasets/77e0b89b413d47dbab97927d5f4dcbe1_9.csv'\n",
    "pv_2014_11_origin = 'https://opendata.arcgis.com/datasets/da64c15a136b4d69ad5a5e3b7b3a8f48_10.csv'\n",
    "pv_2014_12_origin = 'https://opendata.arcgis.com/datasets/b00605a8e3e54d2ca75c525ba42966ea_11.csv'\n",
    "\n",
    "pv_2015_01_origin = 'https://opendata.arcgis.com/datasets/6f36c3fcbcfa4f83931f524628325c9c_0.csv'\n",
    "pv_2015_02_origin = 'https://opendata.arcgis.com/datasets/aab075ac11e9415fb329fb4fab970bc3_1.csv'\n",
    "pv_2015_03_origin = 'https://opendata.arcgis.com/datasets/60c9c95a5fe0436caaa1f80f8b0ecad8_2.csv'\n",
    "pv_2015_04_origin = 'https://opendata.arcgis.com/datasets/c6037ff5ae924f8f845512d7a164abf2_3.csv'\n",
    "pv_2015_05_origin = 'https://opendata.arcgis.com/datasets/f3336832f98d4ccab272c2d3eb1ed3bc_4.csv'\n",
    "pv_2015_06_origin = 'https://opendata.arcgis.com/datasets/33a81b8818eb46b2ac4e14af3c6e56ec_5.csv'\n",
    "pv_2015_07_origin = 'https://opendata.arcgis.com/datasets/0d22a375d1074700b007f67d413b7ee0_6.csv'\n",
    "pv_2015_08_origin = 'https://opendata.arcgis.com/datasets/13fd2526f4da4da294e1bd1ba1b10d4f_7.csv'\n",
    "pv_2015_09_origin = 'https://opendata.arcgis.com/datasets/a0eea990ba9f4ef9a23f94bc8fdb6871_8.csv'\n",
    "pv_2015_10_origin = 'https://opendata.arcgis.com/datasets/58e41f6541bf4c10b94342ba7d7f6442_9.csv'\n",
    "pv_2015_11_origin = 'https://opendata.arcgis.com/datasets/9b040759c7264e59b8943fea0f081725_10.csv'\n",
    "pv_2015_12_origin = 'https://opendata.arcgis.com/datasets/2e967e9053144a309680fccea0f7b4e1_11.csv'\n",
    "\n",
    "pv_2016_01_origin = 'https://opendata.arcgis.com/datasets/7e688a52e65d49c0beef48289860f465_0.csv'\n",
    "pv_2016_02_origin = 'https://opendata.arcgis.com/datasets/150cf72502b344448d900a4f1d779b3a_1.csv'\n",
    "pv_2016_03_origin = 'https://opendata.arcgis.com/datasets/825f603d4cfc41fe9cf9ee74c359f893_2.csv'\n",
    "pv_2016_04_origin = 'https://opendata.arcgis.com/datasets/977602b156f74e41ae2dabbfaca42e20_3.csv'\n",
    "pv_2016_05_origin = 'https://opendata.arcgis.com/datasets/b86079c597e14bc199f2fff0025a1f77_4.csv'\n",
    "pv_2016_06_origin = 'https://opendata.arcgis.com/datasets/897a9bb2a9a1476e8b8f3b984ed1bf8f_5.csv'\n",
    "pv_2016_07_origin = 'https://opendata.arcgis.com/datasets/2a397405e336423d80bf7f94ed5ae7e7_6.csv'\n",
    "pv_2016_08_origin = 'https://opendata.arcgis.com/datasets/34379a1df90c465f8a9f87c26c4e4b04_7.csv'\n",
    "pv_2016_09_origin = 'https://opendata.arcgis.com/datasets/632523fb8bcc4deb9fe9fd05e6765205_8.csv'\n",
    "pv_2016_10_origin = 'https://opendata.arcgis.com/datasets/e0e59dfa9dc24c3491120036de78bc12_9.csv'\n",
    "pv_2016_11_origin = 'https://opendata.arcgis.com/datasets/0bf5acd73f90447789b4c07acff434c5_10.csv'\n",
    "pv_2016_12_origin = 'https://opendata.arcgis.com/datasets/491568da188f4f26bf353633cf41502d_11.csv'\n",
    "\n",
    "pv_2017_01_origin = 'https://opendata.arcgis.com/datasets/421a39b174344bcf90e38b67f03b10a1_0.csv'\n",
    "pv_2017_02_origin = 'https://opendata.arcgis.com/datasets/677a9dfcf4c347dd9757f7fa8d5e95ad_1.csv'\n",
    "pv_2017_03_origin = 'https://opendata.arcgis.com/datasets/4129e4a266cd4b45aa90ee1b7138b7ef_2.csv'\n",
    "pv_2017_04_origin = 'https://opendata.arcgis.com/datasets/3eb5851353a3416da234e185c0583cf0_3.csv'\n",
    "pv_2017_05_origin = 'https://opendata.arcgis.com/datasets/fcd68e3480d3495381a0623e3402e419_4.csv'\n",
    "pv_2017_06_origin = 'https://opendata.arcgis.com/datasets/d5a5b7e20647441985055725e1a17b7d_5.csv'\n",
    "pv_2017_07_origin = 'https://opendata.arcgis.com/datasets/40796e321ad54270a270484b866d5bb6_6.csv'\n",
    "pv_2017_08_origin = 'https://opendata.arcgis.com/datasets/8c0c97bc78d949f18a7180896e6b7b8e_7.csv'\n",
    "pv_2017_09_origin = 'https://opendata.arcgis.com/datasets/4399ad176aab4da5b852dcd7fe0ad4e2_8.csv'\n",
    "pv_2017_10_origin = 'https://opendata.arcgis.com/datasets/275b1ee8dc9a42a8a8f649572f1102cf_9.csv'\n",
    "pv_2017_11_origin = 'https://opendata.arcgis.com/datasets/4454c5c79422425790f69bbef80079cd_10.csv'\n",
    "pv_2017_12_origin = 'https://opendata.arcgis.com/datasets/2b6006eaf7ad421ebf21749f5bac2790_11.csv'\n",
    "\n",
    "pv_2018_01_origin = 'https://opendata.arcgis.com/datasets/2c1b13f7617a4e48b3a31509891eb7e8_0.csv'\n",
    "pv_2018_02_origin = 'https://opendata.arcgis.com/datasets/34fed543751c4243b0c87681ec23040b_1.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read datasets and save it to the local machine for the future usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Once you have a dataset in your local machine, it will be loaded it up directly.\n",
    "# if not, download the datasets directly from Parking Violation, OpenData DC(http://opendata.dc.gov/) \n",
    "\n",
    "\n",
    "## 2014\n",
    "# Parking Violation 2014 Jan datasets\n",
    "\n",
    "\n",
    "if os.path.isfile(pv_2014_01_local) == True:\n",
    "    pv_2014_01 = pd.read_csv(pv_2014_01_local, low_memory=False)\n",
    "else:\n",
    "    pv_2014_01 = pd.read_csv(pv_2014_01_origin, low_memory=False)\n",
    "    pv_2014_01.to_csv(pv_2014_01_local, index=False)\n",
    "\n",
    "\n",
    "### Based on the code below, please write 2014 Jan datasets reading function above    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parking Violation 2014 Feb datasets\n",
    "if os.path.isfile(pv_2014_02_local) == True:\n",
    "    pv_2014_02 = pd.read_csv(pv_2014_02_local, low_memory=False)\n",
    "else:\n",
    "    pv_2014_02 = pd.read_csv(pv_2014_02_origin, low_memory=False)\n",
    "    pv_2014_02.to_csv(pv_2014_02_local, index=False)\n",
    "\n",
    "# Parking Violation 2014 Mar datasets\n",
    "if os.path.isfile(pv_2014_03_local) == True:\n",
    "    pv_2014_03 = pd.read_csv(pv_2014_03_local, low_memory=False)\n",
    "else:\n",
    "    pv_2014_03 = pd.read_csv(pv_2014_03_origin, low_memory=False)\n",
    "    pv_2014_03.to_csv(pv_2014_03_local, index=False)\n",
    "    \n",
    "# Parking Violation 2014 Apr datasets\n",
    "if os.path.isfile(pv_2014_04_local) == True:\n",
    "    pv_2014_04 = pd.read_csv(pv_2014_04_local, low_memory=False)\n",
    "else:\n",
    "    pv_2014_04 = pd.read_csv(pv_2014_04_origin, low_memory=False)\n",
    "    pv_2014_04.to_csv(pv_2014_04_local, index=False)\n",
    "\n",
    "# Parking Violation 2014 May datasets\n",
    "if os.path.isfile(pv_2014_05_local) == True:\n",
    "    pv_2014_05 = pd.read_csv(pv_2014_05_local, low_memory=False)\n",
    "else:\n",
    "    pv_2014_05 = pd.read_csv(pv_2014_05_origin, low_memory=False)\n",
    "    pv_2014_05.to_csv(pv_2014_05_local, index=False)\n",
    "    \n",
    "# Parking Violation 2014 Jun datasets\n",
    "if os.path.isfile(pv_2014_06_local) == True:\n",
    "    pv_2014_06 = pd.read_csv(pv_2014_06_local, low_memory=False)\n",
    "else:\n",
    "    pv_2014_06 = pd.read_csv(pv_2014_06_origin, low_memory=False)\n",
    "    pv_2014_06.to_csv(pv_2014_06_local, index=False)\n",
    "\n",
    "# Parking Violation 2014 Jul datasets\n",
    "if os.path.isfile(pv_2014_07_local) == True:\n",
    "    pv_2014_07 = pd.read_csv(pv_2014_07_local, low_memory=False)\n",
    "else:\n",
    "    pv_2014_07 = pd.read_csv(pv_2014_07_origin, low_memory=False)\n",
    "    pv_2014_07.to_csv(pv_2014_07_local, index=False)\n",
    "    \n",
    "# Parking Violation 2014 Aug datasets\n",
    "if os.path.isfile(pv_2014_08_local) == True:\n",
    "    pv_2014_08 = pd.read_csv(pv_2014_08_local, low_memory=False)\n",
    "else:\n",
    "    pv_2014_08 = pd.read_csv(pv_2014_08_origin, low_memory=False)\n",
    "    pv_2014_08.to_csv(pv_2014_08_local, index=False)\n",
    "    \n",
    "# Parking Violation 2014 Sep datasets\n",
    "if os.path.isfile(pv_2014_09_local) == True:\n",
    "    pv_2014_09 = pd.read_csv(pv_2014_09_local, low_memory=False)\n",
    "else:\n",
    "    pv_2014_09 = pd.read_csv(pv_2014_09_origin, low_memory=False)\n",
    "    pv_2014_09.to_csv(pv_2014_09_local, index=False)\n",
    "    \n",
    "# Parking Violation 2014 Oct datasets\n",
    "if os.path.isfile(pv_2014_10_local) == True:\n",
    "    pv_2014_10 = pd.read_csv(pv_2014_10_local, low_memory=False)\n",
    "else:\n",
    "    pv_2014_10 = pd.read_csv(pv_2014_10_origin, low_memory=False)\n",
    "    pv_2014_10.to_csv(pv_2014_10_local, index=False)\n",
    "    \n",
    "# Parking Violation 2014 Nov datasets\n",
    "if os.path.isfile(pv_2014_11_local) == True:\n",
    "    pv_2014_11 = pd.read_csv(pv_2014_11_local, low_memory=False)\n",
    "else:\n",
    "    pv_2014_11 = pd.read_csv(pv_2014_11_origin, low_memory=False)\n",
    "    pv_2014_11.to_csv(pv_2014_11_local, index=False)\n",
    "    \n",
    "# Parking Violation 2014 Dec datasets\n",
    "if os.path.isfile(pv_2014_12_local) == True:\n",
    "    pv_2014_12 = pd.read_csv(pv_2014_12_local, low_memory=False)\n",
    "else:\n",
    "    pv_2014_12 = pd.read_csv(pv_2014_12_origin, low_memory=False)\n",
    "    pv_2014_12.to_csv(pv_2014_12_local, index=False)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2015\n",
    "# Parking Violation 2015 Jan datasets\n",
    "if os.path.isfile(pv_2015_01_local) == True:\n",
    "    pv_2015_01 = pd.read_csv(pv_2015_01_local, low_memory=False)\n",
    "else:\n",
    "    pv_2015_01 = pd.read_csv(pv_2015_01_origin, low_memory=False)\n",
    "    pv_2015_01.to_csv(pv_2015_01_local, index=False)\n",
    "    \n",
    "# Parking Violation 2015 Feb datasets\n",
    "if os.path.isfile(pv_2015_02_local) == True:\n",
    "    pv_2015_02 = pd.read_csv(pv_2015_02_local, low_memory=False)\n",
    "else:\n",
    "    pv_2015_02 = pd.read_csv(pv_2015_02_origin, low_memory=False)\n",
    "    pv_2015_02.to_csv(pv_2015_02_local, index=False)\n",
    "\n",
    "# Parking Violation 2015 Mar datasets\n",
    "if os.path.isfile(pv_2015_03_local) == True:\n",
    "    pv_2015_03 = pd.read_csv(pv_2015_03_local, low_memory=False)\n",
    "else:\n",
    "    pv_2015_03 = pd.read_csv(pv_2015_03_origin, low_memory=False)\n",
    "    pv_2015_03.to_csv(pv_2015_03_local, index=False)\n",
    "    \n",
    "# Parking Violation 2015 Apr datasets\n",
    "if os.path.isfile(pv_2015_04_local) == True:\n",
    "    pv_2015_04 = pd.read_csv(pv_2015_04_local, low_memory=False)\n",
    "else:\n",
    "    pv_2015_04 = pd.read_csv(pv_2015_04_origin, low_memory=False)\n",
    "    pv_2015_04.to_csv(pv_2015_04_local, index=False)\n",
    "\n",
    "# Parking Violation 2015 May datasets\n",
    "if os.path.isfile(pv_2015_05_local) == True:\n",
    "    pv_2015_05 = pd.read_csv(pv_2015_05_local, low_memory=False)\n",
    "else:\n",
    "    pv_2015_05 = pd.read_csv(pv_2015_05_origin, low_memory=False)\n",
    "    pv_2015_05.to_csv(pv_2015_05_local, index=False)\n",
    "    \n",
    "# Parking Violation 2015 Jun datasets\n",
    "if os.path.isfile(pv_2015_06_local) == True:\n",
    "    pv_2015_06 = pd.read_csv(pv_2015_06_local, low_memory=False)\n",
    "else:\n",
    "    pv_2015_06 = pd.read_csv(pv_2015_06_origin, low_memory=False)\n",
    "    pv_2015_06.to_csv(pv_2015_06_local, index=False)\n",
    "\n",
    "# Parking Violation 2015 Jul datasets\n",
    "if os.path.isfile(pv_2015_07_local) == True:\n",
    "    pv_2015_07 = pd.read_csv(pv_2015_07_local, low_memory=False)\n",
    "else:\n",
    "    pv_2015_07 = pd.read_csv(pv_2015_07_origin, low_memory=False)\n",
    "    pv_2015_07.to_csv(pv_2015_07_local, index=False)\n",
    "    \n",
    "# Parking Violation 2015 Aug datasets\n",
    "if os.path.isfile(pv_2015_08_local) == True:\n",
    "    pv_2015_08 = pd.read_csv(pv_2015_08_local, low_memory=False)\n",
    "else:\n",
    "    pv_2015_08 = pd.read_csv(pv_2015_08_origin, low_memory=False)\n",
    "    pv_2015_08.to_csv(pv_2015_08_local, index=False)\n",
    "    \n",
    "# Parking Violation 2015 Sep datasets\n",
    "if os.path.isfile(pv_2015_09_local) == True:\n",
    "    pv_2015_09 = pd.read_csv(pv_2015_09_local, low_memory=False)\n",
    "else:\n",
    "    pv_2015_09 = pd.read_csv(pv_2015_09_origin, low_memory=False)\n",
    "    pv_2015_09.to_csv(pv_2015_09_local, index=False)\n",
    "    \n",
    "# Parking Violation 2015 Oct datasets\n",
    "if os.path.isfile(pv_2015_10_local) == True:\n",
    "    pv_2015_10 = pd.read_csv(pv_2015_10_local, low_memory=False)\n",
    "else:\n",
    "    pv_2015_10 = pd.read_csv(pv_2015_10_origin, low_memory=False)\n",
    "    pv_2015_10.to_csv(pv_2015_10_local, index=False)\n",
    "    \n",
    "# Parking Violation 2015 Nov datasets\n",
    "if os.path.isfile(pv_2015_11_local) == True:\n",
    "    pv_2015_11 = pd.read_csv(pv_2015_11_local, low_memory=False)\n",
    "else:\n",
    "    pv_2015_11 = pd.read_csv(pv_2015_11_origin, low_memory=False)\n",
    "    pv_2015_11.to_csv(pv_2015_11_local, index=False)\n",
    "    \n",
    "# Parking Violation 2015 Dec datasets\n",
    "if os.path.isfile(pv_2015_12_local) == True:\n",
    "    pv_2015_12 = pd.read_csv(pv_2015_12_local, low_memory=False)\n",
    "else:\n",
    "    pv_2015_12 = pd.read_csv(pv_2015_12_origin, low_memory=False)\n",
    "    pv_2015_12.to_csv(pv_2015_12_local, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2016\n",
    "# Parking Violation 2016 Jan datasets\n",
    "if os.path.isfile(pv_2016_01_local) == True:\n",
    "    pv_2016_01 = pd.read_csv(pv_2016_01_local, low_memory=False)\n",
    "else:\n",
    "    pv_2016_01 = pd.read_csv(pv_2016_01_origin, low_memory=False)\n",
    "    pv_2016_01.to_csv(pv_2016_01_local, index=False)\n",
    "    \n",
    "# Parking Violation 2016 Feb datasets\n",
    "if os.path.isfile(pv_2016_02_local) == True:\n",
    "    pv_2016_02 = pd.read_csv(pv_2016_02_local, low_memory=False)\n",
    "else:\n",
    "    pv_2016_02 = pd.read_csv(pv_2016_02_origin, low_memory=False)\n",
    "    pv_2016_02.to_csv(pv_2016_02_local, index=False)\n",
    "\n",
    "# Parking Violation 2016 Mar datasets\n",
    "if os.path.isfile(pv_2016_03_local) == True:\n",
    "    pv_2016_03 = pd.read_csv(pv_2016_03_local, low_memory=False)\n",
    "else:\n",
    "    pv_2016_03 = pd.read_csv(pv_2016_03_origin, low_memory=False)\n",
    "    pv_2016_03.to_csv(pv_2016_03_local, index=False)\n",
    "    \n",
    "# Parking Violation 2016 Apr datasets\n",
    "if os.path.isfile(pv_2016_04_local) == True:\n",
    "    pv_2016_04 = pd.read_csv(pv_2016_04_local, low_memory=False)\n",
    "else:\n",
    "    pv_2016_04 = pd.read_csv(pv_2016_04_origin, low_memory=False)\n",
    "    pv_2016_04.to_csv(pv_2016_04_local, index=False)\n",
    "\n",
    "# Parking Violation 2016 May datasets\n",
    "if os.path.isfile(pv_2016_05_local) == True:\n",
    "    pv_2016_05 = pd.read_csv(pv_2016_05_local, low_memory=False)\n",
    "else:\n",
    "    pv_2016_05 = pd.read_csv(pv_2016_05_origin, low_memory=False)\n",
    "    pv_2016_05.to_csv(pv_2016_05_local, index=False)\n",
    "    \n",
    "# Parking Violation 2016 Jun datasets\n",
    "if os.path.isfile(pv_2016_06_local) == True:\n",
    "    pv_2016_06 = pd.read_csv(pv_2016_06_local, low_memory=False)\n",
    "else:\n",
    "    pv_2016_06 = pd.read_csv(pv_2016_06_origin, low_memory=False)\n",
    "    pv_2016_06.to_csv(pv_2016_06_local, index=False)\n",
    "\n",
    "# Parking Violation 2016 Jul datasets\n",
    "if os.path.isfile(pv_2016_07_local) == True:\n",
    "    pv_2016_07 = pd.read_csv(pv_2016_07_local, low_memory=False)\n",
    "else:\n",
    "    pv_2016_07 = pd.read_csv(pv_2016_07_origin, low_memory=False)\n",
    "    pv_2016_07.to_csv(pv_2016_07_local, index=False)\n",
    "    \n",
    "# Parking Violation 2016 Aug datasets\n",
    "if os.path.isfile(pv_2016_08_local) == True:\n",
    "    pv_2016_08 = pd.read_csv(pv_2016_08_local, low_memory=False)\n",
    "else:\n",
    "    pv_2016_08 = pd.read_csv(pv_2016_08_origin, low_memory=False)\n",
    "    pv_2016_08.to_csv(pv_2016_08_local, index=False)\n",
    "    \n",
    "# Parking Violation 2016 Sep datasets\n",
    "if os.path.isfile(pv_2016_09_local) == True:\n",
    "    pv_2016_09 = pd.read_csv(pv_2016_09_local, low_memory=False)\n",
    "else:\n",
    "    pv_2016_09 = pd.read_csv(pv_2016_09_origin, low_memory=False)\n",
    "    pv_2016_09.to_csv(pv_2016_09_local, index=False)\n",
    "    \n",
    "# Parking Violation 2016 Oct datasets\n",
    "if os.path.isfile(pv_2016_10_local) == True:\n",
    "    pv_2016_10 = pd.read_csv(pv_2016_10_local, low_memory=False)\n",
    "else:\n",
    "    pv_2016_10 = pd.read_csv(pv_2016_10_origin, low_memory=False)\n",
    "    pv_2016_10.to_csv(pv_2016_10_local, index=False)\n",
    "    \n",
    "# Parking Violation 2016 Nov datasets\n",
    "if os.path.isfile(pv_2016_11_local) == True:\n",
    "    pv_2016_11 = pd.read_csv(pv_2016_11_local, low_memory=False)\n",
    "else:\n",
    "    pv_2016_11 = pd.read_csv(pv_2016_11_origin, low_memory=False)\n",
    "    pv_2016_11.to_csv(pv_2016_11_local, index=False)\n",
    "    \n",
    "# Parking Violation 2016 Dec datasets\n",
    "if os.path.isfile(pv_2016_12_local) == True:\n",
    "    pv_2016_12 = pd.read_csv(pv_2016_12_local, low_memory=False)\n",
    "else:\n",
    "    pv_2016_12 = pd.read_csv(pv_2016_12_origin, low_memory=False)\n",
    "    pv_2016_12.to_csv(pv_2016_12_local, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2017    \n",
    "# Parking Violation 2017 Jan datasets\n",
    "if os.path.isfile(pv_2017_01_local) == True:\n",
    "    pv_2017_01 = pd.read_csv(pv_2017_01_local, low_memory=False)\n",
    "else:\n",
    "    pv_2017_01 = pd.read_csv(pv_2017_01_origin, low_memory=False)\n",
    "    pv_2017_01.to_csv(pv_2017_01_local, index=False)\n",
    "    \n",
    "# Parking Violation 2017 Feb datasets\n",
    "if os.path.isfile(pv_2017_02_local) == True:\n",
    "    pv_2017_02 = pd.read_csv(pv_2017_02_local, low_memory=False)\n",
    "else:\n",
    "    pv_2017_02 = pd.read_csv(pv_2017_02_origin, low_memory=False)\n",
    "    pv_2017_02.to_csv(pv_2017_02_local, index=False)\n",
    "\n",
    "# Parking Violation 2017 Mar datasets\n",
    "if os.path.isfile(pv_2017_03_local) == True:\n",
    "    pv_2017_03 = pd.read_csv(pv_2017_03_local, low_memory=False)\n",
    "else:\n",
    "    pv_2017_03 = pd.read_csv(pv_2017_03_origin, low_memory=False)\n",
    "    pv_2017_03.to_csv(pv_2017_03_local, index=False)\n",
    "    \n",
    "# Parking Violation 2017 Apr datasets\n",
    "if os.path.isfile(pv_2017_04_local) == True:\n",
    "    pv_2017_04 = pd.read_csv(pv_2017_04_local, low_memory=False)\n",
    "else:\n",
    "    pv_2017_04 = pd.read_csv(pv_2017_04_origin, low_memory=False)\n",
    "    pv_2017_04.to_csv(pv_2017_04_local, index=False)\n",
    "\n",
    "# Parking Violation 2017 May datasets\n",
    "if os.path.isfile(pv_2017_05_local) == True:\n",
    "    pv_2017_05 = pd.read_csv(pv_2017_05_local, low_memory=False)\n",
    "else:\n",
    "    pv_2017_05 = pd.read_csv(pv_2017_05_origin, low_memory=False)\n",
    "    pv_2017_05.to_csv(pv_2017_05_local, index=False)\n",
    "    \n",
    "# Parking Violation 2017 Jun datasets\n",
    "if os.path.isfile(pv_2017_06_local) == True:\n",
    "    pv_2017_06 = pd.read_csv(pv_2017_06_local, low_memory=False)\n",
    "else:\n",
    "    pv_2017_06 = pd.read_csv(pv_2017_06_origin, low_memory=False)\n",
    "    pv_2017_06.to_csv(pv_2017_06_local, index=False)\n",
    "\n",
    "# Parking Violation 2017 Jul datasets\n",
    "if os.path.isfile(pv_2017_07_local) == True:\n",
    "    pv_2017_07 = pd.read_csv(pv_2017_07_local, low_memory=False)\n",
    "else:\n",
    "    pv_2017_07 = pd.read_csv(pv_2017_07_origin, low_memory=False)\n",
    "    pv_2017_07.to_csv(pv_2017_07_local, index=False)\n",
    "    \n",
    "# Parking Violation 2017 Aug datasets\n",
    "if os.path.isfile(pv_2017_08_local) == True:\n",
    "    pv_2017_08 = pd.read_csv(pv_2017_08_local, low_memory=False)\n",
    "else:\n",
    "    pv_2017_08 = pd.read_csv(pv_2017_08_origin, low_memory=False)\n",
    "    pv_2017_08.to_csv(pv_2017_08_local, index=False)\n",
    "    \n",
    "# Parking Violation 2017 Sep datasets\n",
    "if os.path.isfile(pv_2017_09_local) == True:\n",
    "    pv_2017_09 = pd.read_csv(pv_2017_09_local, low_memory=False)\n",
    "else:\n",
    "    pv_2017_09 = pd.read_csv(pv_2017_09_origin, low_memory=False)\n",
    "    pv_2017_09.to_csv(pv_2017_09_local, index=False)\n",
    "    \n",
    "# Parking Violation 2017 Oct datasets\n",
    "if os.path.isfile(pv_2017_10_local) == True:\n",
    "    pv_2017_10 = pd.read_csv(pv_2017_10_local, low_memory=False)\n",
    "else:\n",
    "    pv_2017_10 = pd.read_csv(pv_2017_10_origin, low_memory=False)\n",
    "    pv_2017_10.to_csv(pv_2017_10_local, index=False)\n",
    "    \n",
    "# Parking Violation 2017 Nov datasets\n",
    "if os.path.isfile(pv_2017_11_local) == True:\n",
    "    pv_2017_11 = pd.read_csv(pv_2017_11_local, low_memory=False)\n",
    "else:\n",
    "    pv_2017_11 = pd.read_csv(pv_2017_11_origin, low_memory=False)\n",
    "    pv_2017_11.to_csv(pv_2017_11_local, index=False)\n",
    "    \n",
    "# Parking Violation 2017 Dec datasets\n",
    "if os.path.isfile(pv_2017_12_local) == True:\n",
    "    pv_2017_12 = pd.read_csv(pv_2017_12_local, low_memory=False)\n",
    "else:\n",
    "    pv_2017_12 = pd.read_csv(pv_2017_12_origin, low_memory=False)\n",
    "    pv_2017_12.to_csv(pv_2017_12_local, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2018\n",
    "# Parking Violation 2018 Jan datasets\n",
    "if os.path.isfile(pv_2018_01_local) == True:\n",
    "    pv_2018_01 = pd.read_csv(pv_2018_01_local, low_memory=False)\n",
    "else:\n",
    "    pv_2018_01 = pd.read_csv(pv_2018_01_origin, low_memory=False)\n",
    "    pv_2018_01.to_csv(pv_2018_01_local, index=False)\n",
    "    \n",
    "# Parking Violation 2018 Feb datasets\n",
    "if os.path.isfile(pv_2018_02_local) == True:\n",
    "    pv_2018_02 = pd.read_csv(pv_2018_02_local, low_memory=False)\n",
    "else:\n",
    "    pv_2018_02 = pd.read_csv(pv_2018_02_origin, low_memory=False)\n",
    "    pv_2018_02.to_csv(pv_2018_02_local, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concat datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat the datasets\n",
    "\n",
    "# Priya, your answers here\n",
    "\n",
    "pv_2014 = pd.concat([pv_2014_01, pv_2014_02, pv_2014_03, pv_2014_04, pv_2014_05, pv_2014_06, \n",
    "                    pv_2014_07, pv_2014_08, pv_2014_09, pv_2014_10, pv_2014_11, pv_2014_12])\n",
    "print(\"Parking Violation 2014 set shape   : \", pv_2014.shape)\n",
    "\n",
    "### Based on the code below, please write 2014 datasets concatenate each other and print the shape above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_2015 = pd.concat([pv_2015_01, pv_2015_02, pv_2015_03, pv_2015_04, pv_2015_05, pv_2015_06,\n",
    "                     pv_2015_07, pv_2015_08, pv_2015_09, pv_2015_10, pv_2015_11, pv_2015_12])\n",
    "print(\"Parking Violation 2015 set shape   : \", pv_2015.shape)\n",
    "\n",
    "pv_2016 = pd.concat([pv_2016_01, pv_2016_02, pv_2016_03, pv_2016_04, pv_2016_05, pv_2016_06,\n",
    "                     pv_2016_07, pv_2016_08, pv_2016_09, pv_2016_10, pv_2016_11, pv_2016_12])\n",
    "print(\"Parking Violation 2016 set shape   : \", pv_2016.shape)\n",
    "\n",
    "pv_2017 = pd.concat([pv_2017_01, pv_2017_02, pv_2017_03, pv_2017_04, pv_2017_05, pv_2017_06,\n",
    "                     pv_2017_07, pv_2017_08, pv_2017_09, pv_2017_10, pv_2017_11, pv_2017_12])\n",
    "print(\"Parking Violation 2017 set shape   : \", pv_2017.shape)\n",
    "\n",
    "pv_2018 = pd.concat([pv_2018_01, pv_2018_02])\n",
    "print(\"Parking Violation 2018 set shape   : \", pv_2018.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic settings with the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_2014.name       = 'Parking Violation 2014 data'\n",
    "pv_2015.name       = 'Parking Violation 2015 data'\n",
    "pv_2016.name       = 'Parking Violation 2016 data'\n",
    "pv_2017.name       = 'Parking Violation 2017 data'\n",
    "pv_2018.name       = 'Parking Violation 2018 (Jan & Feb) data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that no datasets have `Unnamed: 0` columns in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df_ in [pv_2014, pv_2015, pv_2016, pv_2017, pv_2018]:\n",
    "    if df_.columns[0] == \"Unnamed: 0\":\n",
    "        df_.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "        print(\"Dropped unnamed column in\", df_.name)\n",
    "    else:\n",
    "        print(\"No columns dropped in\", df_.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save it to CSVs (please proceed with the 2nd notebook for the EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save merged PV datasets into the local machine.\n",
    "\n",
    "pv_2014.to_csv('./assets/pv/pv_2014.csv', index=False)\n",
    "pv_2015.to_csv('./assets/pv/pv_2015.csv', index=False)\n",
    "pv_2016.to_csv('./assets/pv/pv_2016.csv', index=False)\n",
    "pv_2017.to_csv('./assets/pv/pv_2017.csv', index=False)\n",
    "pv_2018.to_csv('./assets/pv/pv_2018.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
